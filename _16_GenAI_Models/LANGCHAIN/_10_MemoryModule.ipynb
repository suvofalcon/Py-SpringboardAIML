{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Conversational memory\n",
    "<b>is what enables chatbots to respond to our queries in a conversational manner. It allows for coherent conversations by considering past interactions, rather than treating each query as independent. Without conversational memory, chatbots would lack the ability to remember and build upon previous interactions.</b>\n",
    "\n",
    "By default, chatbot agents are stateless, meaning they process each incoming query as a separate input, without any knowledge of past interactions. They only focus on the current input and don't retain any information from previous interactions.\n",
    "\n",
    "However, in applications like chatbots, it is crucial to remember past interactions. Conversational memory facilitates this by allowing the agent to recall and utilize information from previous conversations.\n",
    "\n",
    "In summary, conversational memory is essential for chatbots to maintain context, recall past interactions, and engage in more meaningful and coherent conversations with users.is what enables chatbots to respond to our queries in a conversational manner. It allows for coherent conversations by considering past interactions, rather than treating each query as independent. Without conversational memory, chatbots would lack the ability to remember and build upon previous interactions.\n",
    "\n",
    "By default, chatbot agents are stateless, meaning they process each incoming query as a separate input, without any knowledge of past interactions. They only focus on the current input and don't retain any information from previous interactions.\n",
    "\n",
    "However, in applications like chatbots, it is crucial to remember past interactions. Conversational memory facilitates this by allowing the agent to recall and utilize information from previous conversations.\n",
    "\n",
    "In summary, conversational memory is essential for chatbots to maintain context, recall past interactions, and engage in more meaningful and coherent conversations with users.\n",
    "\n",
    "<br/><br/>\n",
    "## Different Types of Memory :\n",
    "\n",
    "- ConversationBufferMemory\n",
    "- ConversationBufferWindowMemory\n",
    "- Entity Memory\n",
    "- Conversation Knowledge Graph Memory\n",
    "- ConversationSummaryMemory\n",
    "- ConversationSummaryBufferMemory\n",
    "- ConversationTokenBufferMemory\n",
    "- VectorStore-Backed Memory\n",
    "\n",
    "### Tiktoken\n",
    "Tiktoken, developed by OpenAI, is a tool used for text tokenization. \n",
    "\n",
    "Tokenization involves dividing a text into smaller units, such as letters or words. \n",
    "Tiktoken allows you to count tokens and estimate the cost of using the OpenAI API, which is based on token usage. It utilizes byte pair encoding (BPE), a compression algorithm that replaces frequently occurring pairs of bytes with a single byte.\n",
    "\n",
    "In summary, Tiktoken helps with efficient text processing, token counting, and cost estimation for using OpenAI's API."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fa74ff7eeb4bd4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a08b88d21101903"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-20T11:17:59.620252Z",
     "start_time": "2023-10-20T11:17:58.268391Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import (ConversationBufferMemory, ConversationSummaryMemory, ConversationBufferWindowMemory)\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Initialize OpenAI\n",
    "OpenAI.openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T11:18:00.940672Z",
     "start_time": "2023-10-20T11:18:00.938843Z"
    }
   },
   "id": "e6ec3da7eb0ecc81"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Initialize llm\n",
    "llm = OpenAI(\n",
    "    temperature=0,\n",
    "    model_name='text-davinci-003' #we can also use 'gpt-3.5-turbo'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T11:18:06.987883Z",
     "start_time": "2023-10-20T11:18:06.970300Z"
    }
   },
   "id": "819b826942c29a25"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>What is a Memory?</b>\n",
    "<br>\n",
    "Chains and Agents operate as stateless, treating each query independently. However, in applications like chatbots, its crucial to remember past interactions. The concept of \"Memory\" serves that purpose."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21d86499a6966bda"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ConversationBufferMemory\n",
    "\n",
    "<b>Pros of ConversationBufferMemory:</b>\n",
    "    \n",
    "- Complete conversation history: It retains the entire conversation history, ensuring comprehensive context for the chatbot.\n",
    "- Accurate references: By storing conversation excerpts in their original form, it enables precise referencing to past interactions, enhancing accuracy.\n",
    "- Contextual understanding: The preserved raw form of the conversation helps the chatbot maintain a deep understanding of the ongoing dialogue.\n",
    "- Enhanced responses: With access to the complete conversation history, the chatbot can generate more relevant and coherent responses.\n",
    "     \n",
    "<br/><br/><br/><br/>   \n",
    "<b>Cons of ConversationBufferMemory:</b>\n",
    "\n",
    "- Increased memory usage: Storing the entire conversation history consumes memory resources, potentially leading to memory constraints.\n",
    "- Potential performance impact: Large conversation buffers may slow down processing and response times, affecting the overall system performance.\n",
    "- Limited scalability: As the conversation grows, the memory requirements and processing load may become impractical for extremely long conversations.\n",
    "- Privacy concerns: Storing the entire conversation history raises privacy considerations, as sensitive or personal information may be retained in the buffer."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ab136c6b24528cc"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Now we will create a conversation chain with ConversationBufferMemory\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferMemory()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T11:18:11.659532Z",
     "start_time": "2023-10-20T11:18:11.656518Z"
    }
   },
   "id": "a6e351e5b075fc56"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "# Now we will look at the prompt template that is being sent to LLM\n",
    "print(conversation.prompt.template)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T11:18:12.810691Z",
     "start_time": "2023-10-20T11:18:12.806996Z"
    }
   },
   "id": "1084d92c3ae1fecf"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Good Morning AI\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'Good Morning AI',\n 'history': '',\n 'response': \" Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\"}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will see the conversation getting created\n",
    "conversation(\"Good Morning AI\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T11:18:14.968693Z",
     "start_time": "2023-10-20T11:18:13.708324Z"
    }
   },
   "id": "8af08a0e00faee86"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Good Morning AI\n",
      "AI:  Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\n",
      "Human: My name is Suvo!\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'My name is Suvo!',\n 'history': \"Human: Good Morning AI\\nAI:  Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\",\n 'response': \" Nice to meet you, Suvo! It's a pleasure to make your acquaintance. Is there anything I can do for you today?\"}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"My name is Suvo!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T11:18:48.385876Z",
     "start_time": "2023-10-20T11:18:47.255954Z"
    }
   },
   "id": "ee31af68ea499915"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Good Morning AI\n",
      "AI:  Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\n",
      "Human: My name is Suvo!\n",
      "AI:  Nice to meet you, Suvo! It's a pleasure to make your acquaintance. Is there anything I can do for you today?\n",
      "Human: I stay in kolkata, India\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'I stay in kolkata, India',\n 'history': \"Human: Good Morning AI\\nAI:  Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\\nHuman: My name is Suvo!\\nAI:  Nice to meet you, Suvo! It's a pleasure to make your acquaintance. Is there anything I can do for you today?\",\n 'response': \" Ah, Kolkata! I've heard it's a beautiful city. What do you like most about living there?\"}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"I stay in kolkata, India\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T11:20:10.067954Z",
     "start_time": "2023-10-20T11:20:08.775551Z"
    }
   },
   "id": "c358d74d4f65aa16"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our LLM with ConversationBufferMemory has a special ability to remember past conversations. \n",
    "    \n",
    "<b>It stores and saves the earlier interactions, allowing it to recall and use that information to make better responses. It ensures that the chatbot can keep track of the conversation history for a more coherent experience. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "463c1aa4498c2f68"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Good Morning AI\n",
      "AI:  Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\n",
      "Human: My name is Suvo!\n",
      "AI:  Nice to meet you, Suvo! It's a pleasure to make your acquaintance. Is there anything I can do for you today?\n",
      "Human: I stay in kolkata, India\n",
      "AI:  Ah, Kolkata! I've heard it's a beautiful city. What do you like most about living there?\n"
     ]
    }
   ],
   "source": [
    "# Lets check the complete memory buffer\n",
    "print(conversation.memory.buffer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T12:54:38.782002Z",
     "start_time": "2023-10-20T12:54:38.776153Z"
    }
   },
   "id": "708a1807922c2bea"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Good Morning AI\n",
      "AI:  Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\n",
      "Human: My name is Suvo!\n",
      "AI:  Nice to meet you, Suvo! It's a pleasure to make your acquaintance. Is there anything I can do for you today?\n",
      "Human: I stay in kolkata, India\n",
      "AI:  Ah, Kolkata! I've heard it's a beautiful city. What do you like most about living there?\n",
      "Human: What is my name ?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' You said your name is Suvo. Is that correct?'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will ask the LLM to recall something from the memory\n",
    "conversation.predict(input=\"What is my name ?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T13:02:13.946996Z",
     "start_time": "2023-10-20T13:02:12.931526Z"
    }
   },
   "id": "7dcc5959aa59f204"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ConversationBufferWindow Memory\n",
    "\n",
    "Imagine you have a limited space in your memory to remember recent conversations. \n",
    "<b>   \n",
    "<br>The ConversationBufferWindowMemory is like having a short-term memory that only keeps track of the most recent interactions. It intentionally drops the oldest ones to make room for new ones. \n",
    "</b>\n",
    "<br><br>This helps manage the memory load and reduces the number of tokens used. The important thing is that it still keeps the latest parts of the conversation in their original form, without any modifications. \n",
    "<br>So, it retains the most recent information for the chatbot to refer to, ensuring a more efficient and up-to-date conversation experience.\n",
    "\n",
    "<b>Pros of ConversationBufferWindowMemory:</b>\n",
    "\n",
    "    - Efficient memory utilization: It maintains a limited memory space by only retaining the most recent interactions, optimizing memory usage.\n",
    "    - Reduced token count: Dropping the oldest interactions helps to keep the token count low, preventing potential token limitations.\n",
    "    - Unmodified context retention: The latest parts of the conversation are preserved in their original form, ensuring accurate references and contextual understanding.\n",
    "    - Up-to-date conversations: By focusing on recent interactions, it allows the chatbot to stay current and provide more relevant responses.\n",
    "    \n",
    "**Cons of ConversationBufferWindowMemory:**\n",
    "\n",
    "    - Limited historical context: Since older interactions are intentionally dropped, the chatbot loses access to the complete conversation history, potentially impacting long-term context and accuracy.\n",
    "    - Loss of older information: Valuable insights or details from earlier interactions are not retained, limiting the chatbot's ability to refer back to past conversations.\n",
    "    - Reduced depth of understanding: Without the full conversation history, the chatbot may have a shallower understanding of the user's context and needs.\n",
    "    - Potential loss of context relevance: Important information or context from older interactions may be disregarded, affecting the chatbot's ability to provide comprehensive responses in certain scenarios.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7b248df5b6e4505"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# initialize the conversation\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferWindowMemory()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T13:15:41.089182Z",
     "start_time": "2023-10-20T13:15:41.070929Z"
    }
   },
   "id": "bebd70d05c67f2a8"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "# Lets look at the prompt template\n",
    "print(conversation.prompt.template)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T13:16:23.153277Z",
     "start_time": "2023-10-20T13:16:23.145634Z"
    }
   },
   "id": "47cf7527e5dd79ec"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Good Morning AI!!\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'Good Morning AI!!',\n 'history': '',\n 'response': \" Good morning! It's a beautiful day today, isn't it? I'm feeling quite energized and ready to start the day. How about you?\"}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"Good Morning AI!!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T13:16:54.735610Z",
     "start_time": "2023-10-20T13:16:53.169473Z"
    }
   },
   "id": "3340c8ab507dea3"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Good Morning AI!!\n",
      "AI:  Good morning! It's a beautiful day today, isn't it? I'm feeling quite energized and ready to start the day. How about you?\n",
      "Human: My name is Suvo!\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'My name is Suvo!',\n 'history': \"Human: Good Morning AI!!\\nAI:  Good morning! It's a beautiful day today, isn't it? I'm feeling quite energized and ready to start the day. How about you?\",\n 'response': ' Nice to meet you, Suvo! What can I do for you today?'}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"My name is Suvo!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T13:18:22.359473Z",
     "start_time": "2023-10-20T13:18:21.546576Z"
    }
   },
   "id": "54754928ef5d1ee"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Good Morning AI!!\n",
      "AI:  Good morning! It's a beautiful day today, isn't it? I'm feeling quite energized and ready to start the day. How about you?\n",
      "Human: My name is Suvo!\n",
      "AI:  Nice to meet you, Suvo! What can I do for you today?\n",
      "Human: I stay in kolkata, India\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'I stay in kolkata, India',\n 'history': \"Human: Good Morning AI!!\\nAI:  Good morning! It's a beautiful day today, isn't it? I'm feeling quite energized and ready to start the day. How about you?\\nHuman: My name is Suvo!\\nAI:  Nice to meet you, Suvo! What can I do for you today?\",\n 'response': \" Interesting! Kolkata is a beautiful city. I've heard it's known for its culture and cuisine. What do you like most about living there?\"}"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"I stay in kolkata, India\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T13:18:40.636725Z",
     "start_time": "2023-10-20T13:18:39.432619Z"
    }
   },
   "id": "ab133cc31272c9e3"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Good Morning AI!!\n",
      "AI:  Good morning! It's a beautiful day today, isn't it? I'm feeling quite energized and ready to start the day. How about you?\n",
      "Human: My name is Suvo!\n",
      "AI:  Nice to meet you, Suvo! What can I do for you today?\n",
      "Human: I stay in kolkata, India\n",
      "AI:  Interesting! Kolkata is a beautiful city. I've heard it's known for its culture and cuisine. What do you like most about living there?\n"
     ]
    }
   ],
   "source": [
    "# Lets check the complete memory buffer\n",
    "print(conversation.memory.buffer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T13:19:11.065Z",
     "start_time": "2023-10-20T13:19:11.045499Z"
    }
   },
   "id": "f25c725e293ec8d"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Good Morning AI!!\n",
      "AI:  Good morning! It's a beautiful day today, isn't it? I'm feeling quite energized and ready to start the day. How about you?\n",
      "Human: My name is Suvo!\n",
      "AI:  Nice to meet you, Suvo! What can I do for you today?\n",
      "Human: I stay in kolkata, India\n",
      "AI:  Interesting! Kolkata is a beautiful city. I've heard it's known for its culture and cuisine. What do you like most about living there?\n",
      "Human: What is my name ?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' You said your name is Suvo. Is that correct?'"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will ask the LLM to recall something from the memory\n",
    "conversation.predict(input=\"What is my name ?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T13:19:33.972977Z",
     "start_time": "2023-10-20T13:19:33.335450Z"
    }
   },
   "id": "7819ea84428b785a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3559cb49d5cbe7bb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
