{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression on Ship Dataset\n",
    "\n",
    "Congratulations! You've been contracted by Hyundai Heavy Industries to help them build a predictive model for some ships. [Hyundai Heavy Industries](http://www.hyundai.eu/en) is one of the world's largest ship manufacturing companies and builds cruise liners.\n",
    "\n",
    "You've been flown to their headquarters in Ulsan, South Korea to help them give accurate estimates of how many crew members a ship will require.\n",
    "\n",
    "They are currently building new ships for some customers and want you to create a model and use it to predict how many crew members the ships will need.\n",
    "\n",
    "Here is what the data looks like so far:\n",
    "\n",
    "    Description: Measurements of ship size, capacity, crew, and age for 158 cruise\n",
    "    ships.\n",
    "\n",
    "\n",
    "    Variables/Columns\n",
    "    Ship Name     1-20\n",
    "    Cruise Line   21-40\n",
    "    Age (as of 2013)   46-48\n",
    "    Tonnage (1000s of tons)   50-56\n",
    "    passengers (100s)   58-64\n",
    "    Length (100s of feet)  66-72\n",
    "    Cabins  (100s)   74-80\n",
    "    Passenger Density   82-88\n",
    "    Crew  (100s)   90-96\n",
    "    \n",
    "It is saved in a csv file for you called \"cruise_ship_info.csv\". Your job is to create a regression model that will help predict how many crew members will be needed for future ships. The client also mentioned that they have found that particular cruise lines will differ in acceptable crew counts, so it is most likely an important feature to include in your analysis! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets start by creating Spark Sessions\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('cruise').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- Ship_name: string (nullable = true)\n |-- Cruise_line: string (nullable = true)\n |-- Age: integer (nullable = true)\n |-- Tonnage: double (nullable = true)\n |-- passengers: double (nullable = true)\n |-- length: double (nullable = true)\n |-- cabins: double (nullable = true)\n |-- passenger_density: double (nullable = true)\n |-- crew: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('resources/cruise_ship_info.csv', inferSchema=True, header=True)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n|  Ship_name|Cruise_line|Age|           Tonnage|passengers|length|cabins|passenger_density|crew|\n+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n|    Journey|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n|      Quest|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n|Celebration|   Carnival| 26|            47.262|     14.86|  7.22|  7.43|             31.8| 6.7|\n|   Conquest|   Carnival| 11|             110.0|     29.74|  9.53| 14.88|            36.99|19.1|\n|    Destiny|   Carnival| 17|           101.353|     26.42|  8.92| 13.21|            38.36|10.0|\n|    Ecstasy|   Carnival| 22|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n|    Elation|   Carnival| 15|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n|    Fantasy|   Carnival| 23|            70.367|     20.56|  8.55| 10.22|            34.23| 9.2|\n|Fascination|   Carnival| 19|            70.367|     20.52|  8.55|  10.2|            34.29| 9.2|\n|    Freedom|   Carnival|  6|110.23899999999999|      37.0|  9.51| 14.87|            29.79|11.5|\n+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Lets see few datalines\n",
    "\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+---------+-----------+------------------+------------------+-----------------+-----------------+------------------+-----------------+-----------------+\n|summary|Ship_name|Cruise_line|               Age|           Tonnage|       passengers|           length|            cabins|passenger_density|             crew|\n+-------+---------+-----------+------------------+------------------+-----------------+-----------------+------------------+-----------------+-----------------+\n|  count|      158|        158|               158|               158|              158|              158|               158|              158|              158|\n|   mean| Infinity|       null|15.689873417721518| 71.28467088607599|18.45740506329114|8.130632911392404| 8.830000000000005|39.90094936708861|7.794177215189873|\n| stddev|     null|       null| 7.615691058751413|37.229540025907866|9.677094775143416|1.793473548054825|4.4714172221480615| 8.63921711391542|3.503486564627034|\n|    min|Adventure|    Azamara|                 4|             2.329|             0.66|             2.79|              0.33|             17.7|             0.59|\n|    max|Zuiderdam|   Windstar|                48|             220.0|             54.0|            11.82|              27.0|            71.43|             21.0|\n+-------+---------+-----------+------------------+------------------+-----------------+-----------------+------------------+-----------------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Lets view summary statistics for numerical columns\n",
    "\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------------+\n|      Cruise_line|\n+-----------------+\n|            Costa|\n|              P&O|\n|           Cunard|\n|Regent_Seven_Seas|\n|              MSC|\n|         Carnival|\n|          Crystal|\n|           Orient|\n|         Princess|\n|        Silversea|\n|         Seabourn|\n| Holland_American|\n|         Windstar|\n|           Disney|\n|        Norwegian|\n|          Oceania|\n|          Azamara|\n|        Celebrity|\n|             Star|\n|  Royal_Caribbean|\n+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# We will ignore the Ship_name variable, but use the Cruise_line variable as a categorical variable\n",
    "# Check the unique values\n",
    "df.select('Cruise_line').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------------+-----+\n|      Cruise_line|count|\n+-----------------+-----+\n|            Costa|   11|\n|              P&O|    6|\n|           Cunard|    3|\n|Regent_Seven_Seas|    5|\n|              MSC|    8|\n|         Carnival|   22|\n|          Crystal|    2|\n|           Orient|    1|\n|         Princess|   17|\n|        Silversea|    4|\n|         Seabourn|    3|\n| Holland_American|   14|\n|         Windstar|    3|\n|           Disney|    2|\n|        Norwegian|   13|\n|          Oceania|    3|\n|          Azamara|    2|\n|        Celebrity|   10|\n|             Star|    6|\n|  Royal_Caribbean|   23|\n+-----------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Lets check cruise_line variable by count\n",
    "\n",
    "df.groupBy('Cruise_line').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Row(Ship_name='Journey', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, Cruise_cat=16.0),\n",
       " Row(Ship_name='Quest', Cruise_line='Azamara', Age=6, Tonnage=30.276999999999997, passengers=6.94, length=5.94, cabins=3.55, passenger_density=42.64, crew=3.55, Cruise_cat=16.0),\n",
       " Row(Ship_name='Celebration', Cruise_line='Carnival', Age=26, Tonnage=47.262, passengers=14.86, length=7.22, cabins=7.43, passenger_density=31.8, crew=6.7, Cruise_cat=1.0)]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Cruise line may have an effect as to how many crew members we need\n",
    "\n",
    "# In order to use this variable in the algorithm we would convert it into categorical and assign numerical values\n",
    "# for each of the categories\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"Cruise_line\", outputCol=\"Cruise_cat\")\n",
    "indexed = indexer.fit(df).transform(df)\n",
    "\n",
    "# Check the first three rows for verification\n",
    "indexed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will convert the data into features and labels for the algorithms\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Ship_name',\n",
       " 'Cruise_line',\n",
       " 'Age',\n",
       " 'Tonnage',\n",
       " 'passengers',\n",
       " 'length',\n",
       " 'cabins',\n",
       " 'passenger_density',\n",
       " 'crew',\n",
       " 'Cruise_cat']"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "indexed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['Age', 'Tonnage', 'passengers', 'length', 'cabins', \n",
    "                                       'passenger_density', 'Cruise_cat'],\n",
    "                           outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+----+\n|            features|crew|\n+--------------------+----+\n|[6.0,30.276999999...|3.55|\n|[6.0,30.276999999...|3.55|\n|[26.0,47.262,14.8...| 6.7|\n|[11.0,110.0,29.74...|19.1|\n|[17.0,101.353,26....|10.0|\n|[22.0,70.367,20.5...| 9.2|\n|[15.0,70.367,20.5...| 9.2|\n|[23.0,70.367,20.5...| 9.2|\n|[19.0,70.367,20.5...| 9.2|\n|[6.0,110.23899999...|11.5|\n|[10.0,110.0,29.74...|11.6|\n|[28.0,46.052,14.5...| 6.6|\n|[18.0,70.367,20.5...| 9.2|\n|[17.0,70.367,20.5...| 9.2|\n|[11.0,86.0,21.24,...| 9.3|\n|[8.0,110.0,29.74,...|11.6|\n|[9.0,88.5,21.24,9...|10.3|\n|[15.0,70.367,20.5...| 9.2|\n|[12.0,88.5,21.24,...| 9.3|\n|[20.0,70.367,20.5...| 9.2|\n+--------------------+----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# We will transform the data and create the final dataframe\n",
    "\n",
    "output = assembler.transform(indexed)\n",
    "\n",
    "final_data = output.select('features', 'crew')\n",
    "\n",
    "final_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do a train, test split\n",
    "\n",
    "train_data, test_data = final_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# we will create a Linear regression model object\n",
    "\n",
    "lr = LinearRegression(labelCol='crew')\n",
    "\n",
    "# Fit the model to the data\n",
    "\n",
    "lrmodel = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "coefficients : [-0.014325219988419435,0.006716902017975473,-0.14713140519486861,0.4779449718256105,0.8570924324777663,0.0022912208408813668,0.04818430726512149]\n\n\nIntercept : -1.4875218211025563\n"
     ]
    }
   ],
   "source": [
    "# Get the coefficients and intercept\n",
    "\n",
    "print(f\"coefficients : {lrmodel.coefficients}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Intercept : {lrmodel.intercept}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are going to evaluate this model on test data\n",
    "\n",
    "test_results = lrmodel.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+\n|           residuals|\n+--------------------+\n| 0.43922100476459125|\n| -0.8091203901501052|\n| -1.1966072203035676|\n|  0.4078105401217762|\n| -0.6758720728350998|\n| -0.5746595993770978|\n|  0.9739545363227098|\n|  0.9739545363227098|\n| -0.6098178633633555|\n|-0.33559532459755914|\n|  0.6673696232667918|\n| -1.1573508537167303|\n| -1.4502146898831745|\n| -0.3405661936221378|\n| -1.2330256337283085|\n|   0.247154431896063|\n|  -1.135889469894754|\n| -0.8215923826700102|\n| 0.07243317652413239|\n| -1.6601333835526209|\n+--------------------+\nonly showing top 20 rows\n\nRMSE : 0.7749058544822227\nMSE : 0.6004790833108237\nR2 : 0.9159526022956866\nAdjusted R2 : 0.8963415428313468\n"
     ]
    }
   ],
   "source": [
    "# Get the residuals, RMSE and Adjusted R2\n",
    "\n",
    "test_results.residuals.show()\n",
    "\n",
    "print(f\"RMSE : {test_results.rootMeanSquaredError}\")\n",
    "print(f\"MSE : {test_results.meanSquaredError}\")\n",
    "print(f\"R2 : {test_results.r2}\")\n",
    "print(f\"Adjusted R2 : {test_results.r2adj}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusted R2 of 88% is fairly good... We will inspect the data a little closer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------------------+\n|corr(crew, passengers)|\n+----------------------+\n|    0.9152341306065384|\n+----------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr\n",
    "\n",
    "df.select(corr('crew', 'passengers')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------------+\n|corr(crew, cabins)|\n+------------------+\n|0.9508226063578497|\n+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.select(corr('crew', 'cabins')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('pyspark': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "a8606bb89ff58952fb9d896d3ff97deb9accae9cf8d913f17f7f7ec9d60aa4a4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}