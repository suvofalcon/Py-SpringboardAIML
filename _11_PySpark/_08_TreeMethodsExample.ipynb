{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Methods - Documentation Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the Spark Session\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('rf').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the parse the data file, converting it to a data frame\n",
    "\n",
    "data = spark.read.format('libsvm').load('resources/sample_libsvm_data.txt')\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We will split the data into training and test\n",
    "training_data, test_data = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "training_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will now train a random forest model\n",
    "rf = RandomForestClassifier(labelCol='label', featuresCol='features', numTrees=20)\n",
    "\n",
    "# Train model. This will also fit the indexers\n",
    "model = rf.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|  0.0|(692,[98,99,100,1...|\n",
      "|       0.0|  0.0|(692,[100,101,102...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "|       0.0|  0.0|(692,[126,127,128...|\n",
      "|       0.0|  0.0|(692,[126,127,128...|\n",
      "|       0.0|  0.0|(692,[126,127,128...|\n",
      "|       0.0|  0.0|(692,[126,127,128...|\n",
      "|       0.0|  0.0|(692,[127,128,129...|\n",
      "|       0.0|  0.0|(692,[128,129,130...|\n",
      "|       0.0|  0.0|(692,[150,151,152...|\n",
      "|       0.0|  0.0|(692,[151,152,153...|\n",
      "|       0.0|  0.0|(692,[152,153,154...|\n",
      "|       0.0|  0.0|(692,[152,153,154...|\n",
      "|       0.0|  0.0|(692,[153,154,155...|\n",
      "|       0.0|  0.0|(692,[154,155,156...|\n",
      "|       0.0|  0.0|(692,[181,182,183...|\n",
      "|       0.0|  0.0|(692,[234,235,237...|\n",
      "|       0.0|  1.0|(692,[99,100,101,...|\n",
      "|       1.0|  1.0|(692,[100,101,102...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select example rows to display\n",
    "predictions.select('prediction', 'label', 'features').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9767441860465116\n"
     ]
    }
   ],
   "source": [
    "# Now we will check for prediction, true label and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\n",
    "                                             metricName='accuracy')\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f'Accuracy : {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(692, {205: 0.0037, 216: 0.0072, 244: 0.0357, 262: 0.0401, 273: 0.0366, 328: 0.045, 358: 0.0653, 378: 0.0459, 379: 0.053, 405: 0.05, 406: 0.0184, 407: 0.0462, 427: 0.0395, 434: 0.0163, 439: 0.0068, 461: 0.0467, 462: 0.1527, 490: 0.1, 511: 0.0634, 512: 0.05, 515: 0.003, 540: 0.047, 555: 0.0163, 568: 0.0041, 597: 0.0038, 623: 0.0033})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also get the releative feature importances\n",
    "model.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Trees\n",
    "\n",
    "Gradient-boosted trees (GBTs) are a popular classification and regression method using ensembles of decision trees. More information about the spark.ml implementation can be found further in the section on [GBTs.](http://spark.apache.org/docs/latest/ml-classification-regression.html#gradient-boosted-trees-gbts). For more information on the algorithm itself, please see the [spark.mllib documentation on GBTs.](http://spark.apache.org/docs/latest/mllib-ensembles.html#gradient-boosted-trees-gbts)\n",
    "\n",
    "Luckily Spark makes very easy to use, basically just an import switch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|  0.0|(692,[95,96,97,12...|\n",
      "|       1.0|  0.0|(692,[98,99,100,1...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "|       0.0|  0.0|(692,[126,127,128...|\n",
      "|       0.0|  0.0|(692,[127,128,129...|\n",
      "|       0.0|  0.0|(692,[127,128,129...|\n",
      "|       0.0|  0.0|(692,[152,153,154...|\n",
      "|       0.0|  0.0|(692,[153,154,155...|\n",
      "|       1.0|  0.0|(692,[154,155,156...|\n",
      "|       1.0|  1.0|(692,[123,124,125...|\n",
      "|       1.0|  1.0|(692,[123,124,125...|\n",
      "|       1.0|  1.0|(692,[124,125,126...|\n",
      "|       1.0|  1.0|(692,[124,125,126...|\n",
      "|       1.0|  1.0|(692,[124,125,126...|\n",
      "|       1.0|  1.0|(692,[125,126,127...|\n",
      "|       1.0|  1.0|(692,[126,127,128...|\n",
      "|       1.0|  1.0|(692,[126,127,128...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "# Load and parse the data file\n",
    "\n",
    "data = spark.read.format('libsvm').load('resources/sample_libsvm_data.txt')\n",
    "\n",
    "# Split the data into training and test\n",
    "train_data, test_data = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# We will train a GBT model\n",
    "gbt = GBTClassifier(labelCol='label', featuresCol='features', maxIter=15)\n",
    "\n",
    "# Train the model on data, this also runs the indexers\n",
    "model = gbt.fit(train_data)\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Select rows to display\n",
    "predictions.select('prediction', 'label', 'features').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy to evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction',\n",
    "                                             metricName='accuracy')\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
