{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question and Answer Chat Bots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "We will be working with the Babi Data Set from Facebook Research.\n",
    "\n",
    "Full Details: https://research.fb.com/downloads/babi/\n",
    "\n",
    "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
    "  \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n",
    "  http://arxiv.org/abs/1502.05698\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resources/train_qa.txt', \"rb\") as fp: # Unpickling\n",
    "    train_data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resources/test_qa.txt', \"rb\") as fp: # Unpickling\n",
    "    test_data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Format of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of train_data : <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# The type of the training and test data is a list\n",
    "print(f'The type of train_data : {type(train_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train_data : 10000\n",
      "The length of test_data : 1000\n"
     ]
    }
   ],
   "source": [
    "# Length of the train and test data\n",
    "print(f'The length of train_data : {len(train_data)}')\n",
    "print(f'The length of test_data : {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the first element of the list\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bathroom',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'journeyed',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the story in the first element\n",
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'Sandra', 'in', 'the', 'hallway', '?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the Question in the first element\n",
    "train_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the response in the first element\n",
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Setting up Vocabulary of All Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will use a set in python which is an unordered collection of unique elements\n",
    "vocab = set()\n",
    "\n",
    "all_data = train_data + test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question, answer in all_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the unique words\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the length of the vocab\n",
    "vocab_len = len(vocab) + 1 # we add an extra space to hold a 0 for Keras's pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get the max story length - as the first element [0] is the story and second element is [1] is question\n",
    "max_story_len = max([len(data[0]) for data in all_data])\n",
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])\n",
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is': 1,\n",
       " 'up': 2,\n",
       " 'moved': 3,\n",
       " 'hallway': 4,\n",
       " 'back': 5,\n",
       " 'dropped': 6,\n",
       " 'milk': 7,\n",
       " 'there': 8,\n",
       " '.': 9,\n",
       " 'garden': 10,\n",
       " 'apple': 11,\n",
       " 'to': 12,\n",
       " 'put': 13,\n",
       " '?': 14,\n",
       " 'in': 15,\n",
       " 'no': 16,\n",
       " 'got': 17,\n",
       " 'took': 18,\n",
       " 'mary': 19,\n",
       " 'picked': 20,\n",
       " 'football': 21,\n",
       " 'office': 22,\n",
       " 'bedroom': 23,\n",
       " 'yes': 24,\n",
       " 'john': 25,\n",
       " 'journeyed': 26,\n",
       " 'travelled': 27,\n",
       " 'kitchen': 28,\n",
       " 'down': 29,\n",
       " 'sandra': 30,\n",
       " 'the': 31,\n",
       " 'daniel': 32,\n",
       " 'grabbed': 33,\n",
       " 'bathroom': 34,\n",
       " 'left': 35,\n",
       " 'discarded': 36,\n",
       " 'went': 37}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalize Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    '''\n",
    "    INPUT: \n",
    "    \n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER\n",
    "    Y = []\n",
    "    \n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
    "        #\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=max_story_len),\n",
    "            tf.keras.preprocessing.sequence.pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 31, 23,  9],\n",
       "       [ 0,  0,  0, ..., 31, 10,  9],\n",
       "       [ 0,  0,  0, ..., 31, 10,  9],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 31, 11,  9],\n",
       "       [ 0,  0,  0, ..., 31, 10,  9],\n",
       "       [ 0,  0,  0, ..., 11,  8,  9]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, 25, 15, 31, 28, 14],\n",
       "       [ 1, 25, 15, 31, 28, 14],\n",
       "       [ 1, 25, 15, 31, 10, 14],\n",
       "       ...,\n",
       "       [ 1, 19, 15, 31, 23, 14],\n",
       "       [ 1, 30, 15, 31, 10, 14],\n",
       "       [ 1, 19, 15, 31, 10, 14]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0., 503.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0., 497.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders for Inputs\n",
    "\n",
    "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = tf.keras.layers.Input((max_story_len,))\n",
    "question = tf.keras.layers.Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Networks\n",
    "\n",
    "To understand why we chose this setup, make sure to read the paper we are using:\n",
    "\n",
    "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
    "  \"End-To-End Memory Networks\",\n",
    "  http://arxiv.org/abs/1503.08895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders\n",
    "\n",
    "### Input Encoder m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 0 for pad_sequences\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m = tf.keras.models.Sequential()\n",
    "input_encoder_m.add(tf.keras.layers.Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = tf.keras.models.Sequential()\n",
    "input_encoder_c.add(tf.keras.layers.Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(tf.keras.layers.Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the question into a sequence of vectors\n",
    "question_encoder = tf.keras.models.Sequential()\n",
    "question_encoder.add(tf.keras.layers.Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(tf.keras.layers.Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = tf.keras.layers.dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = tf.keras.layers.Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = tf.keras.layers.add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = tf.keras.layers.Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = tf.keras.layers.concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/Identity:0' shape=(None, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "answer = tf.keras.layers.LSTM(32)(answer)  # (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = tf.keras.layers.Dropout(0.5)(answer)\n",
    "answer = tf.keras.layers.Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we output a probability distribution over the vocabulary\n",
    "answer = tf.keras.layers.Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = tf.keras.models.Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 156)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 156, 6)       0           sequential_2[1][0]               \n",
      "                                                                 sequential_4[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 156, 6)       0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 156, 6)       0           activation[0][0]                 \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 6, 156)       0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute[0][0]                    \n",
      "                                                                 sequential_4[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32)           0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 38)           1254        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 38)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 0.9059 - accuracy: 0.4911 - val_loss: 0.6953 - val_accuracy: 0.5030\n",
      "Epoch 2/120\n",
      "10000/10000 [==============================] - 2s 199us/sample - loss: 0.7029 - accuracy: 0.5115 - val_loss: 0.6993 - val_accuracy: 0.5030\n",
      "Epoch 3/120\n",
      "10000/10000 [==============================] - 2s 199us/sample - loss: 0.6974 - accuracy: 0.4952 - val_loss: 0.6939 - val_accuracy: 0.4970\n",
      "Epoch 4/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.6955 - accuracy: 0.4930 - val_loss: 0.6936 - val_accuracy: 0.5030\n",
      "Epoch 5/120\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.6949 - accuracy: 0.4923 - val_loss: 0.6939 - val_accuracy: 0.5030\n",
      "Epoch 6/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.6943 - accuracy: 0.5081 - val_loss: 0.6934 - val_accuracy: 0.4970\n",
      "Epoch 7/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.6948 - accuracy: 0.4935 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
      "Epoch 8/120\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.6945 - accuracy: 0.5050 - val_loss: 0.6934 - val_accuracy: 0.4970\n",
      "Epoch 9/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.6940 - accuracy: 0.5014 - val_loss: 0.6982 - val_accuracy: 0.4970\n",
      "Epoch 10/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.6940 - accuracy: 0.5064 - val_loss: 0.6943 - val_accuracy: 0.4970\n",
      "Epoch 11/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.6940 - accuracy: 0.5042 - val_loss: 0.6947 - val_accuracy: 0.4740\n",
      "Epoch 12/120\n",
      "10000/10000 [==============================] - 2s 204us/sample - loss: 0.6937 - accuracy: 0.5107 - val_loss: 0.6959 - val_accuracy: 0.4820\n",
      "Epoch 13/120\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.6916 - accuracy: 0.5262 - val_loss: 0.6952 - val_accuracy: 0.5080\n",
      "Epoch 14/120\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.6897 - accuracy: 0.5280 - val_loss: 0.6908 - val_accuracy: 0.5090\n",
      "Epoch 15/120\n",
      "10000/10000 [==============================] - 2s 204us/sample - loss: 0.6720 - accuracy: 0.5812 - val_loss: 0.6585 - val_accuracy: 0.6050\n",
      "Epoch 16/120\n",
      "10000/10000 [==============================] - 2s 204us/sample - loss: 0.6160 - accuracy: 0.6648 - val_loss: 0.5670 - val_accuracy: 0.7090\n",
      "Epoch 17/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.5395 - accuracy: 0.7380 - val_loss: 0.5048 - val_accuracy: 0.7570\n",
      "Epoch 18/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.4920 - accuracy: 0.7751 - val_loss: 0.4713 - val_accuracy: 0.7930\n",
      "Epoch 19/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.4623 - accuracy: 0.7917 - val_loss: 0.4490 - val_accuracy: 0.7910\n",
      "Epoch 20/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.4404 - accuracy: 0.8120 - val_loss: 0.4264 - val_accuracy: 0.8130\n",
      "Epoch 21/120\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.4155 - accuracy: 0.8280 - val_loss: 0.4141 - val_accuracy: 0.8160\n",
      "Epoch 22/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.3988 - accuracy: 0.8359 - val_loss: 0.3979 - val_accuracy: 0.8330\n",
      "Epoch 23/120\n",
      "10000/10000 [==============================] - 2s 204us/sample - loss: 0.3841 - accuracy: 0.8398 - val_loss: 0.3911 - val_accuracy: 0.8270\n",
      "Epoch 24/120\n",
      "10000/10000 [==============================] - 2s 205us/sample - loss: 0.3778 - accuracy: 0.8401 - val_loss: 0.4035 - val_accuracy: 0.8290\n",
      "Epoch 25/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.3601 - accuracy: 0.8459 - val_loss: 0.3885 - val_accuracy: 0.8300\n",
      "Epoch 26/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.3565 - accuracy: 0.8526 - val_loss: 0.3741 - val_accuracy: 0.8210\n",
      "Epoch 27/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.3495 - accuracy: 0.8542 - val_loss: 0.3624 - val_accuracy: 0.8260\n",
      "Epoch 28/120\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.3490 - accuracy: 0.8545 - val_loss: 0.3760 - val_accuracy: 0.8170\n",
      "Epoch 29/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.3389 - accuracy: 0.8535 - val_loss: 0.3709 - val_accuracy: 0.8200\n",
      "Epoch 30/120\n",
      "10000/10000 [==============================] - 2s 200us/sample - loss: 0.3394 - accuracy: 0.8551 - val_loss: 0.3545 - val_accuracy: 0.8300\n",
      "Epoch 31/120\n",
      "10000/10000 [==============================] - 2s 200us/sample - loss: 0.3316 - accuracy: 0.8561 - val_loss: 0.3515 - val_accuracy: 0.8340\n",
      "Epoch 32/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.3261 - accuracy: 0.8582 - val_loss: 0.3621 - val_accuracy: 0.8310\n",
      "Epoch 33/120\n",
      "10000/10000 [==============================] - 2s 204us/sample - loss: 0.3258 - accuracy: 0.8617 - val_loss: 0.3506 - val_accuracy: 0.8380\n",
      "Epoch 34/120\n",
      "10000/10000 [==============================] - 2s 205us/sample - loss: 0.3253 - accuracy: 0.8581 - val_loss: 0.3573 - val_accuracy: 0.8340\n",
      "Epoch 35/120\n",
      "10000/10000 [==============================] - 2s 200us/sample - loss: 0.3183 - accuracy: 0.8621 - val_loss: 0.3626 - val_accuracy: 0.8250\n",
      "Epoch 36/120\n",
      "10000/10000 [==============================] - 2s 205us/sample - loss: 0.3177 - accuracy: 0.8655 - val_loss: 0.3673 - val_accuracy: 0.8320\n",
      "Epoch 37/120\n",
      "10000/10000 [==============================] - 2s 204us/sample - loss: 0.3202 - accuracy: 0.8633 - val_loss: 0.3535 - val_accuracy: 0.8310\n",
      "Epoch 38/120\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.3132 - accuracy: 0.8650 - val_loss: 0.3537 - val_accuracy: 0.8400\n",
      "Epoch 39/120\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.3170 - accuracy: 0.8630 - val_loss: 0.3588 - val_accuracy: 0.8310\n",
      "Epoch 40/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.3137 - accuracy: 0.8650 - val_loss: 0.3527 - val_accuracy: 0.8320\n",
      "Epoch 41/120\n",
      "10000/10000 [==============================] - 2s 204us/sample - loss: 0.3054 - accuracy: 0.8678 - val_loss: 0.3616 - val_accuracy: 0.8330\n",
      "Epoch 42/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.3119 - accuracy: 0.8666 - val_loss: 0.3519 - val_accuracy: 0.8340\n",
      "Epoch 43/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.3064 - accuracy: 0.8686 - val_loss: 0.3438 - val_accuracy: 0.8320\n",
      "Epoch 44/120\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.3025 - accuracy: 0.8705 - val_loss: 0.3725 - val_accuracy: 0.8240\n",
      "Epoch 45/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.3053 - accuracy: 0.8667 - val_loss: 0.3625 - val_accuracy: 0.8340\n",
      "Epoch 46/120\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.3006 - accuracy: 0.8693 - val_loss: 0.3507 - val_accuracy: 0.8330\n",
      "Epoch 47/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.2997 - accuracy: 0.8689 - val_loss: 0.3444 - val_accuracy: 0.8310\n",
      "Epoch 48/120\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.2982 - accuracy: 0.8732 - val_loss: 0.3438 - val_accuracy: 0.8320\n",
      "Epoch 49/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.3008 - accuracy: 0.8712 - val_loss: 0.3765 - val_accuracy: 0.8320\n",
      "Epoch 50/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.2984 - accuracy: 0.8710 - val_loss: 0.3619 - val_accuracy: 0.8360\n",
      "Epoch 51/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.3042 - accuracy: 0.8691 - val_loss: 0.3569 - val_accuracy: 0.8360\n",
      "Epoch 52/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.2950 - accuracy: 0.8741 - val_loss: 0.3752 - val_accuracy: 0.8320\n",
      "Epoch 53/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.2986 - accuracy: 0.8697 - val_loss: 0.3609 - val_accuracy: 0.8310\n",
      "Epoch 54/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.2924 - accuracy: 0.8718 - val_loss: 0.3569 - val_accuracy: 0.8290\n",
      "Epoch 55/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.2926 - accuracy: 0.8738 - val_loss: 0.3759 - val_accuracy: 0.8300\n",
      "Epoch 56/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.2868 - accuracy: 0.8756 - val_loss: 0.4116 - val_accuracy: 0.8210\n",
      "Epoch 57/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.2917 - accuracy: 0.8717 - val_loss: 0.3785 - val_accuracy: 0.8270\n",
      "Epoch 58/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.2894 - accuracy: 0.8745 - val_loss: 0.3653 - val_accuracy: 0.8350\n",
      "Epoch 59/120\n",
      "10000/10000 [==============================] - 2s 200us/sample - loss: 0.2889 - accuracy: 0.8749 - val_loss: 0.3838 - val_accuracy: 0.8300\n",
      "Epoch 60/120\n",
      "10000/10000 [==============================] - 2s 200us/sample - loss: 0.2868 - accuracy: 0.8759 - val_loss: 0.3707 - val_accuracy: 0.8340\n",
      "Epoch 61/120\n",
      "10000/10000 [==============================] - 2s 200us/sample - loss: 0.2888 - accuracy: 0.8760 - val_loss: 0.3866 - val_accuracy: 0.8200\n",
      "Epoch 62/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.2872 - accuracy: 0.8764 - val_loss: 0.3789 - val_accuracy: 0.8350\n",
      "Epoch 63/120\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.2851 - accuracy: 0.8742 - val_loss: 0.3725 - val_accuracy: 0.8330\n",
      "Epoch 64/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.2788 - accuracy: 0.8782 - val_loss: 0.3723 - val_accuracy: 0.8340\n",
      "Epoch 65/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.2826 - accuracy: 0.8777 - val_loss: 0.3666 - val_accuracy: 0.8370\n",
      "Epoch 66/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.2853 - accuracy: 0.8790 - val_loss: 0.3957 - val_accuracy: 0.8240\n",
      "Epoch 67/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.2813 - accuracy: 0.8756 - val_loss: 0.3842 - val_accuracy: 0.8320\n",
      "Epoch 68/120\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.2791 - accuracy: 0.8793 - val_loss: 0.3849 - val_accuracy: 0.8300\n",
      "Epoch 69/120\n",
      "10000/10000 [==============================] - 2s 200us/sample - loss: 0.2756 - accuracy: 0.8811 - val_loss: 0.3804 - val_accuracy: 0.8300\n",
      "Epoch 70/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.2744 - accuracy: 0.8825 - val_loss: 0.3770 - val_accuracy: 0.8370\n",
      "Epoch 71/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.2771 - accuracy: 0.8837 - val_loss: 0.3838 - val_accuracy: 0.8270\n",
      "Epoch 72/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.2727 - accuracy: 0.8812 - val_loss: 0.3973 - val_accuracy: 0.8330\n",
      "Epoch 73/120\n",
      "10000/10000 [==============================] - 2s 199us/sample - loss: 0.2727 - accuracy: 0.8813 - val_loss: 0.3828 - val_accuracy: 0.8210\n",
      "Epoch 74/120\n",
      "10000/10000 [==============================] - 2s 200us/sample - loss: 0.2733 - accuracy: 0.8798 - val_loss: 0.4151 - val_accuracy: 0.8280\n",
      "Epoch 75/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.2666 - accuracy: 0.8831 - val_loss: 0.4008 - val_accuracy: 0.8250\n",
      "Epoch 76/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.2705 - accuracy: 0.8806 - val_loss: 0.3993 - val_accuracy: 0.8370\n",
      "Epoch 77/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.2657 - accuracy: 0.8849 - val_loss: 0.3946 - val_accuracy: 0.8340\n",
      "Epoch 78/120\n",
      "10000/10000 [==============================] - 2s 200us/sample - loss: 0.2623 - accuracy: 0.8842 - val_loss: 0.4148 - val_accuracy: 0.8360\n",
      "Epoch 79/120\n",
      "10000/10000 [==============================] - 2s 200us/sample - loss: 0.2633 - accuracy: 0.8858 - val_loss: 0.4281 - val_accuracy: 0.8280\n",
      "Epoch 80/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.2720 - accuracy: 0.8827 - val_loss: 0.4134 - val_accuracy: 0.8280\n",
      "Epoch 81/120\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.2655 - accuracy: 0.8857 - val_loss: 0.4248 - val_accuracy: 0.8240\n",
      "Epoch 82/120\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.2594 - accuracy: 0.8891 - val_loss: 0.4091 - val_accuracy: 0.8280\n",
      "Epoch 83/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.2593 - accuracy: 0.8881 - val_loss: 0.4263 - val_accuracy: 0.8330\n",
      "Epoch 84/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.2583 - accuracy: 0.8904 - val_loss: 0.4210 - val_accuracy: 0.8310\n",
      "Epoch 85/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.2607 - accuracy: 0.8900 - val_loss: 0.4298 - val_accuracy: 0.8330\n",
      "Epoch 86/120\n",
      "10000/10000 [==============================] - 2s 206us/sample - loss: 0.2592 - accuracy: 0.8890 - val_loss: 0.4172 - val_accuracy: 0.8270\n",
      "Epoch 87/120\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.2559 - accuracy: 0.8884 - val_loss: 0.4306 - val_accuracy: 0.8250\n",
      "Epoch 88/120\n",
      "10000/10000 [==============================] - 2s 204us/sample - loss: 0.2531 - accuracy: 0.8909 - val_loss: 0.4049 - val_accuracy: 0.8340\n",
      "Epoch 89/120\n",
      "10000/10000 [==============================] - 2s 204us/sample - loss: 0.2566 - accuracy: 0.8885 - val_loss: 0.4334 - val_accuracy: 0.8230\n",
      "Epoch 90/120\n",
      "10000/10000 [==============================] - 2s 204us/sample - loss: 0.2510 - accuracy: 0.8917 - val_loss: 0.4366 - val_accuracy: 0.8350\n",
      "Epoch 91/120\n",
      "10000/10000 [==============================] - 2s 205us/sample - loss: 0.2520 - accuracy: 0.8922 - val_loss: 0.4310 - val_accuracy: 0.8290\n",
      "Epoch 92/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.2490 - accuracy: 0.8909 - val_loss: 0.4627 - val_accuracy: 0.8330\n",
      "Epoch 93/120\n",
      "10000/10000 [==============================] - 2s 204us/sample - loss: 0.2497 - accuracy: 0.8907 - val_loss: 0.4358 - val_accuracy: 0.8360\n",
      "Epoch 94/120\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.2452 - accuracy: 0.8939 - val_loss: 0.4280 - val_accuracy: 0.8320\n",
      "Epoch 95/120\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.2481 - accuracy: 0.8905 - val_loss: 0.4477 - val_accuracy: 0.8330\n",
      "Epoch 96/120\n",
      "10000/10000 [==============================] - 2s 204us/sample - loss: 0.2452 - accuracy: 0.8949 - val_loss: 0.4517 - val_accuracy: 0.8320\n",
      "Epoch 97/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.2434 - accuracy: 0.8925 - val_loss: 0.4551 - val_accuracy: 0.8270\n",
      "Epoch 98/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.2441 - accuracy: 0.8977 - val_loss: 0.4341 - val_accuracy: 0.8310\n",
      "Epoch 99/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.2402 - accuracy: 0.8964 - val_loss: 0.4668 - val_accuracy: 0.8260\n",
      "Epoch 100/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.2433 - accuracy: 0.8972 - val_loss: 0.4592 - val_accuracy: 0.8270\n",
      "Epoch 101/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.2376 - accuracy: 0.8978 - val_loss: 0.4356 - val_accuracy: 0.8250\n",
      "Epoch 102/120\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.2376 - accuracy: 0.8958 - val_loss: 0.4630 - val_accuracy: 0.8240\n",
      "Epoch 103/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.2350 - accuracy: 0.8994 - val_loss: 0.5185 - val_accuracy: 0.8280\n",
      "Epoch 104/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.2383 - accuracy: 0.8980 - val_loss: 0.4770 - val_accuracy: 0.8230\n",
      "Epoch 105/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.2314 - accuracy: 0.9003 - val_loss: 0.4965 - val_accuracy: 0.8190\n",
      "Epoch 106/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.2370 - accuracy: 0.9000 - val_loss: 0.4537 - val_accuracy: 0.8290\n",
      "Epoch 107/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.2263 - accuracy: 0.9054 - val_loss: 0.5313 - val_accuracy: 0.8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/120\n",
      "10000/10000 [==============================] - 2s 203us/sample - loss: 0.2331 - accuracy: 0.8999 - val_loss: 0.4997 - val_accuracy: 0.8150\n",
      "Epoch 109/120\n",
      "10000/10000 [==============================] - 2s 199us/sample - loss: 0.2338 - accuracy: 0.9007 - val_loss: 0.4864 - val_accuracy: 0.8260\n",
      "Epoch 110/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.2280 - accuracy: 0.9016 - val_loss: 0.4526 - val_accuracy: 0.8240\n",
      "Epoch 111/120\n",
      "10000/10000 [==============================] - 2s 200us/sample - loss: 0.2292 - accuracy: 0.9037 - val_loss: 0.5063 - val_accuracy: 0.8240\n",
      "Epoch 112/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.2340 - accuracy: 0.8959 - val_loss: 0.4850 - val_accuracy: 0.8260\n",
      "Epoch 113/120\n",
      "10000/10000 [==============================] - 2s 200us/sample - loss: 0.2300 - accuracy: 0.9005 - val_loss: 0.5007 - val_accuracy: 0.8200\n",
      "Epoch 114/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.2206 - accuracy: 0.9042 - val_loss: 0.4983 - val_accuracy: 0.8200\n",
      "Epoch 115/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.2213 - accuracy: 0.9067 - val_loss: 0.5109 - val_accuracy: 0.8290\n",
      "Epoch 116/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.2248 - accuracy: 0.9049 - val_loss: 0.5167 - val_accuracy: 0.8200\n",
      "Epoch 117/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.2229 - accuracy: 0.9052 - val_loss: 0.5413 - val_accuracy: 0.8180\n",
      "Epoch 118/120\n",
      "10000/10000 [==============================] - 2s 200us/sample - loss: 0.2249 - accuracy: 0.9037 - val_loss: 0.5295 - val_accuracy: 0.8160\n",
      "Epoch 119/120\n",
      "10000/10000 [==============================] - 2s 201us/sample - loss: 0.2178 - accuracy: 0.9062 - val_loss: 0.5131 - val_accuracy: 0.8250\n",
      "Epoch 120/120\n",
      "10000/10000 [==============================] - 2s 202us/sample - loss: 0.2159 - accuracy: 0.9082 - val_loss: 0.5420 - val_accuracy: 0.8160\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32, epochs=120, \n",
    "                    validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'chatbot_120_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "### Plotting Out Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on Given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filename)\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.99995375\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Your Own Stories and Questions\n",
    "\n",
    "Remember you can only use words from the existing vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the whitespace of the periods\n",
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(),my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.68924487\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
