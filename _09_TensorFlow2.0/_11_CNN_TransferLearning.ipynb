{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Demonstrate Transfer Learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n!wget --no-check-certificate     https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5     -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\\n'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "'''\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 74, 74, 32)   96          conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 74, 74, 32)   0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 72, 72, 32)   9216        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 72, 72, 32)   96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 72, 72, 32)   0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 72, 72, 64)   18432       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 72, 72, 64)   192         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 72, 72, 64)   0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 35, 35, 80)   240         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 35, 35, 80)   0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 33, 33, 192)  138240      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 33, 33, 192)  576         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 33, 33, 192)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 16, 16, 96)   55296       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 16, 16, 48)   144         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 16, 16, 96)   288         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 16, 16, 48)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 16, 16, 96)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 16, 16, 192)  0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 16, 16, 64)   76800       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 16, 16, 96)   82944       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 16, 16, 64)   192         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 16, 16, 64)   192         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 16, 16, 32)   96          conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 16, 16, 64)   0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 16, 16, 64)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 16, 16, 96)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 16, 16, 32)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_99[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 16, 16, 96)   55296       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 16, 16, 48)   144         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 16, 16, 96)   288         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 16, 16, 48)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 16, 16, 96)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 16, 16, 64)   76800       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 16, 16, 96)   82944       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 16, 16, 64)   192         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 16, 16, 64)   192         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 16, 16, 64)   192         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 16, 16, 64)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 16, 16, 64)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 16, 16, 96)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 16, 16, 64)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_106[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 16, 16, 96)   55296       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 16, 16, 48)   144         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 16, 16, 96)   288         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 16, 16, 48)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 16, 16, 96)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 16, 16, 64)   76800       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 16, 16, 96)   82944       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 16, 16, 64)   192         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 16, 16, 64)   192         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 16, 16, 64)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 16, 16, 96)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 16, 16, 64)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_113[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "                                                                 activation_118[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 16, 16, 64)   192         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 16, 16, 64)   0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 16, 16, 96)   55296       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 16, 16, 96)   288         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 16, 16, 96)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 7, 7, 96)     82944       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 7, 7, 384)    1152        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 7, 7, 96)     288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 7, 7, 384)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 7, 7, 96)     0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 7, 7, 128)    384         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 7, 7, 128)    0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 7, 7, 128)    114688      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 7, 7, 128)    0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 7, 7, 128)    384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 7, 7, 128)    0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 7, 7, 128)    0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 7, 7, 128)    114688      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 7, 7, 128)    0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 7, 7, 192)    172032      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 7, 7, 192)    172032      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 7, 7, 192)    576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 7, 7, 192)    576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 7, 7, 192)    576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 7, 7, 192)    0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 7, 7, 192)    0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 7, 7, 192)    0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 7, 7, 160)    480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 7, 7, 160)    0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 7, 7, 160)    179200      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 7, 7, 160)    0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 7, 7, 160)    480         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 7, 7, 160)    0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 7, 7, 160)    179200      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 7, 7, 160)    0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 7, 7, 192)    215040      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 7, 7, 192)    215040      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 7, 7, 192)    576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 7, 7, 192)    576         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 7, 7, 192)    0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 7, 7, 192)    0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 7, 7, 192)    0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_134[0][0]             \n",
      "                                                                 activation_137[0][0]             \n",
      "                                                                 activation_142[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 7, 7, 160)    480         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 7, 7, 160)    0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 7, 7, 160)    179200      activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 7, 7, 160)    0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 7, 7, 160)    480         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 7, 7, 160)    0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 7, 7, 160)    0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 7, 7, 160)    179200      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 7, 7, 160)    0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 7, 7, 192)    215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 7, 7, 192)    215040      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 7, 7, 192)    576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 7, 7, 192)    576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 7, 7, 192)    0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 7, 7, 192)    0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 7, 7, 192)    0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "                                                                 activation_152[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 7, 7, 192)    0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 7, 7, 192)    258048      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 7, 7, 192)    0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 7, 7, 192)    0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 7, 7, 192)    0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 7, 7, 192)    258048      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 7, 7, 192)    0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 7, 7, 192)    0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 7, 7, 192)    0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 7, 7, 192)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_154[0][0]             \n",
      "                                                                 activation_157[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 7, 7, 192)    576         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 7, 7, 192)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 7, 7, 192)    258048      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 7, 7, 192)    576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 7, 7, 192)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 7, 7, 192)    258048      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 7, 7, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 7, 7, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 7, 7, 192)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 7, 7, 192)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 3, 3, 320)    552960      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 3, 3, 192)    331776      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 3, 3, 320)    960         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 3, 3, 192)    576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 3, 3, 320)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 3, 3, 192)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_165[0][0]             \n",
      "                                                                 activation_169[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 3, 3, 448)    1344        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 3, 3, 448)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 3, 3, 384)    1548288     activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 3, 3, 384)    1152        conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 3, 3, 384)    1152        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 3, 3, 384)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 3, 3, 384)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 3, 3, 384)    1152        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 3, 3, 384)    1152        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 3, 3, 384)    1152        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 3, 3, 384)    1152        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 3, 3, 320)    960         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 3, 3, 384)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 3, 3, 384)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 3, 3, 384)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 3, 3, 384)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 3, 3, 192)    576         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 3, 3, 320)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_172[0][0]             \n",
      "                                                                 activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3, 3, 768)    0           activation_176[0][0]             \n",
      "                                                                 activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 3, 3, 192)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_170[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 3, 3, 448)    1344        conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 3, 3, 448)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 3, 3, 384)    1548288     activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 3, 3, 384)    1152        conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 3, 3, 384)    1152        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 3, 3, 384)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 3, 3, 384)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 3, 3, 384)    1152        conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 3, 3, 384)    1152        conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 3, 3, 384)    1152        conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 3, 3, 384)    1152        conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 3, 3, 320)    960         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 3, 3, 384)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 3, 3, 384)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 3, 3, 384)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 3, 3, 384)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 3, 3, 192)    576         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 3, 3, 320)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_181[0][0]             \n",
      "                                                                 activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 3, 3, 768)    0           activation_185[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 3, 3, 192)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_179[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_187[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the inception v3 model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "local_weights_file ='inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape=(150, 150, 3),\n",
    "                                include_top=False, # InceptionV3 has a fully connected layer at the top .. we want to ignore this and go straight to the convolutions\n",
    "                                weights=None) # We would want to use the weights from the local file and not the weights which model comes with\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False # The model will not be re-trained here, we are using the already learned convolutions\n",
    "\n",
    "pre_trained_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Now we will add our own DNN at the bottom of these, which we can retrain on our data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-trained model layer output shape: (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "# All of the layers have names.. We will inspect the one which has lot of convolutions.. (we can use other layer as well)\n",
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print(f'pre-trained model layer output shape: {last_layer.output_shape}')\n",
    "last_output = last_layer.output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "# Now we will add the DNN to the last_output\n",
    "\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1024 neurons and activation relu\n",
    "x = layers.Dense(1024, activation=tf.nn.relu)(x)\n",
    "# Add a dropout rate of 0.2\n",
    "'''\n",
    "The idea behind Dropouts is that they remove a random number of neurons in your neural network. This works very well for two reasons: The first is that neighboring neurons often end up with similar weights, which can lead to overfitting, so dropping some out at random can remove this. The second is that often a neuron can over-weigh the input from a neuron in the previous layer, and can over specialize as a result. Thus, dropping out can break the neural network out of this potential bad habit!\n",
    "'''\n",
    "x = layers.Dropout(0.2)(x)\n",
    "# Add the final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation=tf.nn.sigmoid)(x)\n",
    "\n",
    "# We will add in the layers definition which we created to the built in model instantiated earlier\n",
    "model = Model(pre_trained_model.input, x)\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Now we will add this pre-trained defined model to our own data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Five file names for cats images training - ['cat.0.jpg', 'cat.1.jpg', 'cat.10.jpg', 'cat.100.jpg', 'cat.101.jpg']\n",
      "Five file names for dogs images training - ['dog.0.jpg', 'dog.1.jpg', 'dog.10.jpg', 'dog.100.jpg', 'dog.101.jpg']\n",
      "Total training cats images - 1000\n",
      "Total training dogs images - 1000\n",
      "Total validation cats images - 500\n",
      "Total validation dogs images - 500\n"
     ]
    }
   ],
   "source": [
    "# Declare the directory paths\n",
    "parent_dir = '../../../LargeDatasets/CNNDatasets/cats_and_dogs_filtered'\n",
    "train_dir = os.path.join(parent_dir, 'train')\n",
    "validation_dir = os.path.join(parent_dir, 'validation')\n",
    "\n",
    "# Directory for training images\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Directory for validation images\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "# Check first five file names of cats and dogs\n",
    "train_cats_fnames = os.listdir(train_cats_dir)\n",
    "train_dogs_fnames = os.listdir(train_dogs_dir)\n",
    "print(f\"Five file names for cats images training - {train_cats_fnames[:5]}\")\n",
    "print(f\"Five file names for dogs images training - {train_dogs_fnames[:5]}\")\n",
    "\n",
    "# Also find out the total number of images available for each classes in the directories\n",
    "print(f\"Total training cats images - {len(os.listdir(train_cats_dir))}\")\n",
    "print(f\"Total training dogs images - {len(os.listdir(train_dogs_dir))}\")\n",
    "print(f\"Total validation cats images - {len(os.listdir(validation_cats_dir))}\")\n",
    "print(f\"Total validation dogs images - {len(os.listdir(validation_dogs_dir))}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Preprocess the image before we apply the images to the model for training\n",
    "\n",
    "# Adding data augmentation parameters\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "# Note that validation data should not be augmented\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(150, 150))\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
    "                                                        batch_size=20,\n",
    "                                                        class_mode='binary',\n",
    "                                                        target_size=(150, 150))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 27s 215ms/step - loss: 1.3099 - accuracy: 0.8235 - val_loss: 0.2433 - val_accuracy: 0.9130\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 14s 143ms/step - loss: 0.3418 - accuracy: 0.8905 - val_loss: 0.1103 - val_accuracy: 0.9540\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.3195 - accuracy: 0.9100 - val_loss: 0.2023 - val_accuracy: 0.9430\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 14s 143ms/step - loss: 0.3087 - accuracy: 0.9090 - val_loss: 0.0992 - val_accuracy: 0.9710\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.2774 - accuracy: 0.9190 - val_loss: 0.1076 - val_accuracy: 0.9660\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.2595 - accuracy: 0.9165 - val_loss: 0.1140 - val_accuracy: 0.9610\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.2195 - accuracy: 0.9285 - val_loss: 0.1178 - val_accuracy: 0.9640\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 0.2295 - accuracy: 0.9330 - val_loss: 0.1193 - val_accuracy: 0.9670\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.2403 - accuracy: 0.9310 - val_loss: 0.1263 - val_accuracy: 0.9600\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 0.2043 - accuracy: 0.9350 - val_loss: 0.1719 - val_accuracy: 0.9520\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 0.1914 - accuracy: 0.9450 - val_loss: 0.1289 - val_accuracy: 0.9650\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 0.2097 - accuracy: 0.9395 - val_loss: 0.1419 - val_accuracy: 0.9550\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.1958 - accuracy: 0.9410 - val_loss: 0.1185 - val_accuracy: 0.9680\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 15s 146ms/step - loss: 0.1782 - accuracy: 0.9500 - val_loss: 0.1407 - val_accuracy: 0.9700\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.2128 - accuracy: 0.9340 - val_loss: 0.1143 - val_accuracy: 0.9700\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 14s 143ms/step - loss: 0.1929 - accuracy: 0.9485 - val_loss: 0.0988 - val_accuracy: 0.9700\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 0.1874 - accuracy: 0.9375 - val_loss: 0.1267 - val_accuracy: 0.9600\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 15s 145ms/step - loss: 0.1604 - accuracy: 0.9510 - val_loss: 0.1446 - val_accuracy: 0.9690\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 14s 141ms/step - loss: 0.1476 - accuracy: 0.9480 - val_loss: 0.1069 - val_accuracy: 0.9690\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 0.1734 - accuracy: 0.9520 - val_loss: 0.1669 - val_accuracy: 0.9490\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    steps_per_epoch=100,\n",
    "                    epochs=20,\n",
    "                    validation_steps=50,\n",
    "                    verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy and validation loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}