{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tensor Operations\r\n",
    "This section covers:\r\n",
    "* Indexing and slicing\r\n",
    "* Reshaping tensors (tensor views)\r\n",
    "* Tensor arithmetic and basic operations\r\n",
    "* Dot products\r\n",
    "* Matrix multiplication\r\n",
    "* Additional, more advanced operations\r\n",
    "\r\n",
    "## Perform standard imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\r\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Indexing and slicing\r\n",
    "Extracting specific values from a tensor works just the same as with NumPy arrays<br>\r\n",
    "<img src='../Images/arrayslicing.png' width=\"500\" style=\"display: inline-block\"><br><br>\r\n",
    "Image source: http://www.scipy-lectures.org/_images/numpy_indexing.png"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "x = torch.arange(6).reshape(3, 2)\r\n",
    "print(x)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Grabbing the right hand column values\r\n",
    "x[:, 1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1, 3, 5])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Grabbing the right hand column values as a (3, 1) slice\r\n",
    "x[:, 1:]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [3],\n",
       "        [5]])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reshape tensors with .view()\r\n",
    "\r\n",
    "view() and reshape() do essentially the same thing by returning a reshaped tensor without changing the original tensor in place.\r\n",
    "There's a good discussion of the differences here."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "x = torch.arange(10)\r\n",
    "print(x)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "x.view(2, 5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# x is unchanged\r\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Views reflect the most current data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "z = x.view(2, 5)\r\n",
    "x[0] = 234\r\n",
    "print(z)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[234,   1,   2,   3,   4],\n",
      "        [  5,   6,   7,   8,   9]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Views can infer the correct size\r\n",
    "By passing in -1 PyTorch will infer the correct value from the given tensor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "x.view(2, -1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[234,   1,   2,   3,   4],\n",
       "        [  5,   6,   7,   8,   9]])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "x.view(-1, 5)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[234,   1,   2,   3,   4],\n",
       "        [  5,   6,   7,   8,   9]])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Adopt another tensor's shape with .view_as()\r\n",
    "\r\n",
    "view_as(input) only works with tensors that have the same number of elements."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "x.view_as(z)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[234,   1,   2,   3,   4],\n",
       "        [  5,   6,   7,   8,   9]])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tensor Arithmetic\r\n",
    "\r\n",
    "Adding tensors can be performed a few different ways depending on the desired result.\r\n",
    "\r\n",
    "As a simple expression:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "a = torch.tensor([1, 2, 3], dtype=torch.float)\r\n",
    "b = torch.tensor([4, 5, 6], dtype=torch.float)\r\n",
    "print(f\"Adding two tensors - {a + b}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Adding two tensors - tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Or it can also be done as\r\n",
    "print(torch.add(a, b))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "with an output tensor passed in as an argument"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "result = torch.empty(3)\r\n",
    "torch.add(a, b, out=result)\r\n",
    "print(result)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Changing a tensor in-place"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "a.add_(b)\r\n",
    "print(a)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([5., 7., 9.])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-info\"><strong>NOTE:</strong> Any operation that changes a tensor in-place is post-fixed with an underscore _.\r\n",
    "    <br>In the above example: <tt>a.add_(b)</tt> changed <tt>a</tt>.</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Basic Tensor Operations\r\n",
    "<table style=\"display: inline-block\">\r\n",
    "<caption style=\"text-align: center\"><strong>Arithmetic</strong></caption>\r\n",
    "<tr><th>OPERATION</th><th>FUNCTION</th><th>DESCRIPTION</th></tr>\r\n",
    "<tr><td>a + b</td><td>a.add(b)</td><td>element wise addition</td></tr>\r\n",
    "<tr><td>a - b</td><td>a.sub(b)</td><td>subtraction</td></tr>\r\n",
    "<tr><td>a * b</td><td>a.mul(b)</td><td>multiplication</td></tr>\r\n",
    "<tr><td>a / b</td><td>a.div(b)</td><td>division</td></tr>\r\n",
    "<tr><td>a % b</td><td>a.fmod(b)</td><td>modulo (remainder after division)</td></tr>\r\n",
    "<tr><td>a<sup>b</sup></td><td>a.pow(b)</td><td>power</td></tr>\r\n",
    "<tr><td>&nbsp;</td><td></td><td></td></tr>\r\n",
    "</table>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<table style=\"display: inline-block\">\r\n",
    "<caption style=\"text-align: center\"><strong>Monomial Operations</strong></caption>\r\n",
    "<tr><th>OPERATION</th><th>FUNCTION</th><th>DESCRIPTION</th></tr>\r\n",
    "<tr><td>|a|</td><td>torch.abs(a)</td><td>absolute value</td></tr>\r\n",
    "<tr><td>1/a</td><td>torch.reciprocal(a)</td><td>reciprocal</td></tr>\r\n",
    "<tr><td>$\\sqrt{a}$</td><td>torch.sqrt(a)</td><td>square root</td></tr>\r\n",
    "<tr><td>log(a)</td><td>torch.log(a)</td><td>natural log</td></tr>\r\n",
    "<tr><td>e<sup>a</sup></td><td>torch.exp(a)</td><td>exponential</td></tr>\r\n",
    "<tr><td>12.34  ==>  12.</td><td>torch.trunc(a)</td><td>truncated integer</td></tr>\r\n",
    "<tr><td>12.34  ==>  0.34</td><td>torch.frac(a)</td><td>fractional component</td></tr>\r\n",
    "</table> <br><br>\r\n",
    "\r\n",
    "<table style=\"display: inline-block\">\r\n",
    "<caption style=\"text-align: center\"><strong>Trigonometry</strong></caption>\r\n",
    "<tr><th>OPERATION</th><th>FUNCTION</th><th>DESCRIPTION</th></tr>\r\n",
    "<tr><td>sin(a)</td><td>torch.sin(a)</td><td>sine</td></tr>\r\n",
    "<tr><td>cos(a)</td><td>torch.sin(a)</td><td>cosine</td></tr>\r\n",
    "<tr><td>tan(a)</td><td>torch.sin(a)</td><td>tangent</td></tr>\r\n",
    "<tr><td>arcsin(a)</td><td>torch.asin(a)</td><td>arc sine</td></tr>\r\n",
    "<tr><td>arccos(a)</td><td>torch.acos(a)</td><td>arc cosine</td></tr>\r\n",
    "<tr><td>arctan(a)</td><td>torch.atan(a)</td><td>arc tangent</td></tr>\r\n",
    "<tr><td>sinh(a)</td><td>torch.sinh(a)</td><td>hyperbolic sine</td></tr>\r\n",
    "<tr><td>cosh(a)</td><td>torch.cosh(a)</td><td>hyperbolic cosine</td></tr>\r\n",
    "<tr><td>tanh(a)</td><td>torch.tanh(a)</td><td>hyperbolic tangent</td></tr>\r\n",
    "</table> <br><br>\r\n",
    "\r\n",
    "<table style=\"display: inline-block\">\r\n",
    "<caption style=\"text-align: center\"><strong>Summary Statistics</strong></caption>\r\n",
    "<tr><th>OPERATION</th><th>FUNCTION</th><th>DESCRIPTION</th></tr>\r\n",
    "<tr><td>$\\sum a$</td><td>torch.sum(a)</td><td>sum</td></tr>\r\n",
    "<tr><td>$\\bar a$</td><td>torch.mean(a)</td><td>mean</td></tr>\r\n",
    "<tr><td>a<sub>max</sub></td><td>torch.max(a)</td><td>maximum</td></tr>\r\n",
    "<tr><td>a<sub>min</sub></td><td>torch.min(a)</td><td>minimum</td></tr>\r\n",
    "<tr><td colspan=\"3\">torch.max(a,b) returns a tensor of size a<br>containing the element wise max between a and b</td></tr>\r\n",
    "</table> <br><br>\r\n",
    "\r\n",
    "<div class=\"alert alert-info\"><strong>NOTE:</strong> Most arithmetic operations require float values. Those that do work with integers return integer tensors.<br>\r\n",
    "For example, <tt>torch.div(a,b)</tt> performs floor division (truncates the decimal) for integer types, and classic division for floats.</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "a = torch.tensor([1,2,3], dtype=torch.float)\r\n",
    "b = torch.tensor([4,5,6], dtype=torch.float)\r\n",
    "print(torch.add(a,b).sum())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(21.)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dot products\r\n",
    "A <a href='https://en.wikipedia.org/wiki/Dot_product'>dot product</a> is the sum of the products of the corresponding entries of two 1D tensors. If the tensors are both vectors, the dot product is given as:<br>\r\n",
    "\r\n",
    "$\\begin{bmatrix} a & b & c \\end{bmatrix} \\;\\cdot\\; \\begin{bmatrix} d & e & f \\end{bmatrix} = ad + be + cf$\r\n",
    "\r\n",
    "If the tensors include a column vector, then the dot product is the sum of the result of the multiplied matrices. For example:<br>\r\n",
    "$\\begin{bmatrix} a & b & c \\end{bmatrix} \\;\\cdot\\; \\begin{bmatrix} d \\\\ e \\\\ f \\end{bmatrix} = ad + be + cf$<br><br>\r\n",
    "Dot products can be expressed as <a href='https://pytorch.org/docs/stable/torch.html#torch.dot'><strong><tt>torch.dot(a,b)</tt></strong></a> or `a.dot(b)` or `b.dot(a)`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "a = torch.tensor([1, 2, 3], dtype=torch.float)\r\n",
    "b = torch.tensor([4, 5, 6], dtype=torch.float)\r\n",
    "print(a.mul(b)) # for reference\r\n",
    "print()\r\n",
    "print(a.dot(b))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([ 4., 10., 18.])\n",
      "\n",
      "tensor(32.)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-info\"><strong>NOTE:</strong> There's a slight difference between <tt>torch.dot()</tt> and <tt>numpy.dot()</tt>. While <tt>torch.dot()</tt> only accepts 1D arguments and returns a dot product, <tt>numpy.dot()</tt> also accepts 2D arguments and performs matrix multiplication. We show matrix multiplication below.</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Matrix multiplication\r\n",
    "2D <a href='https://en.wikipedia.org/wiki/Matrix_multiplication'>Matrix multiplication</a> is possible when the number of columns in tensor <strong><tt>A</tt></strong> matches the number of rows in tensor <strong><tt>B</tt></strong>. In this case, the product of tensor <strong><tt>A</tt></strong> with size $(x,y)$ and tensor <strong><tt>B</tt></strong> with size $(y,z)$ results in a tensor of size $(x,z)$\r\n",
    "<div>\r\n",
    "<div align=\"left\"><img src='../Images/Matrix_multiplication_diagram.png' align=\"left\"><br><br>\r\n",
    "\r\n",
    "$\\begin{bmatrix} a & b & c \\\\\r\n",
    "d & e & f \\end{bmatrix} \\;\\times\\; \\begin{bmatrix} m & n \\\\ p & q \\\\ r & s \\end{bmatrix} = \\begin{bmatrix} (am+bp+cr) & (an+bq+cs) \\\\\r\n",
    "(dm+ep+fr) & (dn+eq+fs) \\end{bmatrix}$</div></div>\r\n",
    "\r\n",
    "<div style=\"clear:both\">Image source: <a href='https://commons.wikimedia.org/wiki/File:Matrix_multiplication_diagram_2.svg'>https://commons.wikimedia.org/wiki/File:Matrix_multiplication_diagram_2.svg</a></div>\r\n",
    "\r\n",
    "Matrix multiplication can be computed using <a href='https://pytorch.org/docs/stable/torch.html#torch.mm'><strong><tt>torch.mm(a,b)</tt></strong></a> or `a.mm(b)` or `a @ b`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "a = torch.tensor([[0, 2, 4], [1, 3, 5]], dtype=torch.float)\r\n",
    "b = torch.tensor([[6, 7], [8, 9], [10, 11]], dtype=torch.float)\r\n",
    "\r\n",
    "print(f\"Size of matrix a - {a.size()}\")\r\n",
    "print(f\"Size of matrix b - {b.size()}\")\r\n",
    "print(f\"Multiplication of both matrix - {torch.mm(a, b)}\")\r\n",
    "print(f\"Size of the result matrix - {torch.mm(a, b).size()}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Size of matrix a - torch.Size([2, 3])\n",
      "Size of matrix b - torch.Size([3, 2])\n",
      "Multiplication of both matrix - tensor([[56., 62.],\n",
      "        [80., 89.]])\n",
      "Size of the result matrix - torch.Size([2, 2])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "print(a.mm(b))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[56., 62.],\n",
      "        [80., 89.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "print(a@b)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[56., 62.],\n",
      "        [80., 89.]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Matrix multiplication with broadcasting\r\n",
    "Matrix multiplication that involves <a href='https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics'>broadcasting</a> can be computed using <a href='https://pytorch.org/docs/stable/torch.html#torch.matmul'><strong><tt>torch.matmul(a,b)</tt></strong></a> or `a.matmul(b)` or `a @ b`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "t1 = torch.randn(2, 3, 4)\r\n",
    "t2 = torch.randn(4, 5)\r\n",
    "print(torch.matmul(t1, t2).size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "torch.randn(2, 3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 1.3142, -0.0450,  1.0585],\n",
       "        [ 0.9823, -1.2540, -0.2689]])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, the same operation raises a <tt><strong>RuntimeError</strong></tt> with <tt>torch.mm()</tt>:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "print(torch.mm(t1, t2).size())"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "self must be a matrix",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5456/2270689567.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: self must be a matrix"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## L2 or Euclidian Norm\r\n",
    "See <a href='https://pytorch.org/docs/stable/torch.html#torch.norm'><strong><tt>torch.norm()</tt></strong></a>\r\n",
    "\r\n",
    "The <a href='https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm'>Euclidian Norm</a> gives the vector norm of $x$ where $x=(x_1,x_2,...,x_n)$.<br>\r\n",
    "It is calculated as<br>\r\n",
    "\r\n",
    "${\\displaystyle \\left\\|{\\boldsymbol {x}}\\right\\|_{2}:={\\sqrt {x_{1}^{2}+\\cdots +x_{n}^{2}}}}$\r\n",
    "\r\n",
    "\r\n",
    "When applied to a matrix, <tt>torch.norm()</tt> returns the <a href='https://en.wikipedia.org/wiki/Matrix_norm#Frobenius_norm'>Frobenius norm</a> by default."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "x = torch.tensor([2.,5.,8.,14.])\r\n",
    "x.norm()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(17.)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Number of elements\r\n",
    "See <a href='https://pytorch.org/docs/stable/torch.html#torch.numel'><strong><tt>torch.numel()</tt></strong></a>\r\n",
    "\r\n",
    "Returns the number of elements in a tensor."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "x = torch.ones(3,7)\r\n",
    "x.numel()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('pytorch-gpu': conda)"
  },
  "interpreter": {
   "hash": "3e1efc7545cd46da8113c1188a7f61bc3259aaf8f10b04b41145a683344e547b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}